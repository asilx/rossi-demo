"""autogenerated by genmsg_py from FeatureCalculationRequest.msg. Do not edit."""
import roslib.message
import struct


class FeatureCalculationRequest(roslib.message.Message):
  _md5sum = "b8c57ae607be14b9e0810ec7ae9914ec"
  _type = "feature_factory/FeatureCalculationRequest"
  _has_header = False #flag to mark the presence of a Header object
  _full_text = """bool calc_amplitude
bool calc_confidence
bool calc_distance
bool calc_normals_azi
bool calc_normals_zen

"""
  __slots__ = ['calc_amplitude','calc_confidence','calc_distance','calc_normals_azi','calc_normals_zen']
  _slot_types = ['bool','bool','bool','bool','bool']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.
    
    The available fields are:
       calc_amplitude,calc_confidence,calc_distance,calc_normals_azi,calc_normals_zen
    
    @param args: complete set of field values, in .msg order
    @param kwds: use keyword arguments corresponding to message field names
    to set specific fields. 
    """
    if args or kwds:
      super(FeatureCalculationRequest, self).__init__(*args, **kwds)
      #message fields cannot be None, assign default values for those that are
      if self.calc_amplitude is None:
        self.calc_amplitude = False
      if self.calc_confidence is None:
        self.calc_confidence = False
      if self.calc_distance is None:
        self.calc_distance = False
      if self.calc_normals_azi is None:
        self.calc_normals_azi = False
      if self.calc_normals_zen is None:
        self.calc_normals_zen = False
    else:
      self.calc_amplitude = False
      self.calc_confidence = False
      self.calc_distance = False
      self.calc_normals_azi = False
      self.calc_normals_zen = False

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    @param buff: buffer
    @type  buff: StringIO
    """
    try:
      _x = self
      buff.write(_struct_5B.pack(_x.calc_amplitude, _x.calc_confidence, _x.calc_distance, _x.calc_normals_azi, _x.calc_normals_zen))
    except struct.error as se: self._check_types(se)
    except TypeError as te: self._check_types(te)

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    @param str: byte array of serialized message
    @type  str: str
    """
    try:
      end = 0
      _x = self
      start = end
      end += 5
      (_x.calc_amplitude, _x.calc_confidence, _x.calc_distance, _x.calc_normals_azi, _x.calc_normals_zen,) = _struct_5B.unpack(str[start:end])
      self.calc_amplitude = bool(self.calc_amplitude)
      self.calc_confidence = bool(self.calc_confidence)
      self.calc_distance = bool(self.calc_distance)
      self.calc_normals_azi = bool(self.calc_normals_azi)
      self.calc_normals_zen = bool(self.calc_normals_zen)
      return self
    except struct.error as e:
      raise roslib.message.DeserializationError(e) #most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    @param buff: buffer
    @type  buff: StringIO
    @param numpy: numpy python module
    @type  numpy module
    """
    try:
      _x = self
      buff.write(_struct_5B.pack(_x.calc_amplitude, _x.calc_confidence, _x.calc_distance, _x.calc_normals_azi, _x.calc_normals_zen))
    except struct.error as se: self._check_types(se)
    except TypeError as te: self._check_types(te)

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    @param str: byte array of serialized message
    @type  str: str
    @param numpy: numpy python module
    @type  numpy: module
    """
    try:
      end = 0
      _x = self
      start = end
      end += 5
      (_x.calc_amplitude, _x.calc_confidence, _x.calc_distance, _x.calc_normals_azi, _x.calc_normals_zen,) = _struct_5B.unpack(str[start:end])
      self.calc_amplitude = bool(self.calc_amplitude)
      self.calc_confidence = bool(self.calc_confidence)
      self.calc_distance = bool(self.calc_distance)
      self.calc_normals_azi = bool(self.calc_normals_azi)
      self.calc_normals_zen = bool(self.calc_normals_zen)
      return self
    except struct.error as e:
      raise roslib.message.DeserializationError(e) #most likely buffer underfill

_struct_I = roslib.message.struct_I
_struct_5B = struct.Struct("<5B")
"""autogenerated by genmsg_py from FeatureCalculationResponse.msg. Do not edit."""
import roslib.message
import struct

import std_msgs.msg
import sensor_msgs.msg

class FeatureCalculationResponse(roslib.message.Message):
  _md5sum = "f24ae207f2df8c90f50cdb3329739f1d"
  _type = "feature_factory/FeatureCalculationResponse"
  _has_header = False #flag to mark the presence of a Header object
  _full_text = """sensor_msgs/PointCloud2 f_distances
sensor_msgs/PointCloud2 f_confidences
sensor_msgs/PointCloud2 f_amplitudes
sensor_msgs/PointCloud2 f_normals_azi
sensor_msgs/PointCloud2 f_normals_zen


================================================================================
MSG: sensor_msgs/PointCloud2
# This message holds a collection of N-dimensional points, which may
# contain additional information such as normals, intensity, etc. The
# point data is stored as a binary blob, its layout described by the
# contents of the "fields" array.

# The point cloud data may be organized 2d (image-like) or 1d
# (unordered). Point clouds organized as 2d images may be produced by
# camera depth sensors such as stereo or time-of-flight.

# Time of sensor data acquisition, and the coordinate frame ID (for 3d
# points).
Header header

# 2D structure of the point cloud. If the cloud is unordered, height is
# 1 and width is the length of the point cloud.
uint32 height
uint32 width

# Describes the channels and their layout in the binary data blob.
PointField[] fields

bool    is_bigendian # Is this data bigendian?
uint32  point_step   # Length of a point in bytes
uint32  row_step     # Length of a row in bytes
uint8[] data         # Actual point data, size is (row_step*height)

bool is_dense        # True if there are no invalid points

================================================================================
MSG: std_msgs/Header
# Standard metadata for higher-level stamped data types.
# This is generally used to communicate timestamped data 
# in a particular coordinate frame.
# 
# sequence ID: consecutively increasing ID 
uint32 seq
#Two-integer timestamp that is expressed as:
# * stamp.secs: seconds (stamp_secs) since epoch
# * stamp.nsecs: nanoseconds since stamp_secs
# time-handling sugar is provided by the client library
time stamp
#Frame this data is associated with
# 0: no frame
# 1: global frame
string frame_id

================================================================================
MSG: sensor_msgs/PointField
# This message holds the description of one point entry in the
# PointCloud2 message format.
uint8 INT8    = 1
uint8 UINT8   = 2
uint8 INT16   = 3
uint8 UINT16  = 4
uint8 INT32   = 5
uint8 UINT32  = 6
uint8 FLOAT32 = 7
uint8 FLOAT64 = 8

string name      # Name of field
uint32 offset    # Offset from start of point struct
uint8  datatype  # Datatype enumeration, see above
uint32 count     # How many elements in the field

"""
  __slots__ = ['f_distances','f_confidences','f_amplitudes','f_normals_azi','f_normals_zen']
  _slot_types = ['sensor_msgs/PointCloud2','sensor_msgs/PointCloud2','sensor_msgs/PointCloud2','sensor_msgs/PointCloud2','sensor_msgs/PointCloud2']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.
    
    The available fields are:
       f_distances,f_confidences,f_amplitudes,f_normals_azi,f_normals_zen
    
    @param args: complete set of field values, in .msg order
    @param kwds: use keyword arguments corresponding to message field names
    to set specific fields. 
    """
    if args or kwds:
      super(FeatureCalculationResponse, self).__init__(*args, **kwds)
      #message fields cannot be None, assign default values for those that are
      if self.f_distances is None:
        self.f_distances = sensor_msgs.msg.PointCloud2()
      if self.f_confidences is None:
        self.f_confidences = sensor_msgs.msg.PointCloud2()
      if self.f_amplitudes is None:
        self.f_amplitudes = sensor_msgs.msg.PointCloud2()
      if self.f_normals_azi is None:
        self.f_normals_azi = sensor_msgs.msg.PointCloud2()
      if self.f_normals_zen is None:
        self.f_normals_zen = sensor_msgs.msg.PointCloud2()
    else:
      self.f_distances = sensor_msgs.msg.PointCloud2()
      self.f_confidences = sensor_msgs.msg.PointCloud2()
      self.f_amplitudes = sensor_msgs.msg.PointCloud2()
      self.f_normals_azi = sensor_msgs.msg.PointCloud2()
      self.f_normals_zen = sensor_msgs.msg.PointCloud2()

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    @param buff: buffer
    @type  buff: StringIO
    """
    try:
      _x = self
      buff.write(_struct_3I.pack(_x.f_distances.header.seq, _x.f_distances.header.stamp.secs, _x.f_distances.header.stamp.nsecs))
      _x = self.f_distances.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_distances.height, _x.f_distances.width))
      length = len(self.f_distances.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_distances.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_distances.is_bigendian, _x.f_distances.point_step, _x.f_distances.row_step))
      _x = self.f_distances.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_B3I.pack(_x.f_distances.is_dense, _x.f_confidences.header.seq, _x.f_confidences.header.stamp.secs, _x.f_confidences.header.stamp.nsecs))
      _x = self.f_confidences.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_confidences.height, _x.f_confidences.width))
      length = len(self.f_confidences.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_confidences.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_confidences.is_bigendian, _x.f_confidences.point_step, _x.f_confidences.row_step))
      _x = self.f_confidences.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_B3I.pack(_x.f_confidences.is_dense, _x.f_amplitudes.header.seq, _x.f_amplitudes.header.stamp.secs, _x.f_amplitudes.header.stamp.nsecs))
      _x = self.f_amplitudes.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_amplitudes.height, _x.f_amplitudes.width))
      length = len(self.f_amplitudes.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_amplitudes.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_amplitudes.is_bigendian, _x.f_amplitudes.point_step, _x.f_amplitudes.row_step))
      _x = self.f_amplitudes.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_B3I.pack(_x.f_amplitudes.is_dense, _x.f_normals_azi.header.seq, _x.f_normals_azi.header.stamp.secs, _x.f_normals_azi.header.stamp.nsecs))
      _x = self.f_normals_azi.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_normals_azi.height, _x.f_normals_azi.width))
      length = len(self.f_normals_azi.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_normals_azi.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_normals_azi.is_bigendian, _x.f_normals_azi.point_step, _x.f_normals_azi.row_step))
      _x = self.f_normals_azi.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_B3I.pack(_x.f_normals_azi.is_dense, _x.f_normals_zen.header.seq, _x.f_normals_zen.header.stamp.secs, _x.f_normals_zen.header.stamp.nsecs))
      _x = self.f_normals_zen.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_normals_zen.height, _x.f_normals_zen.width))
      length = len(self.f_normals_zen.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_normals_zen.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_normals_zen.is_bigendian, _x.f_normals_zen.point_step, _x.f_normals_zen.row_step))
      _x = self.f_normals_zen.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      buff.write(_struct_B.pack(self.f_normals_zen.is_dense))
    except struct.error as se: self._check_types(se)
    except TypeError as te: self._check_types(te)

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    @param str: byte array of serialized message
    @type  str: str
    """
    try:
      if self.f_distances is None:
        self.f_distances = sensor_msgs.msg.PointCloud2()
      if self.f_confidences is None:
        self.f_confidences = sensor_msgs.msg.PointCloud2()
      if self.f_amplitudes is None:
        self.f_amplitudes = sensor_msgs.msg.PointCloud2()
      if self.f_normals_azi is None:
        self.f_normals_azi = sensor_msgs.msg.PointCloud2()
      if self.f_normals_zen is None:
        self.f_normals_zen = sensor_msgs.msg.PointCloud2()
      end = 0
      _x = self
      start = end
      end += 12
      (_x.f_distances.header.seq, _x.f_distances.header.stamp.secs, _x.f_distances.header.stamp.nsecs,) = _struct_3I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_distances.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_distances.height, _x.f_distances.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_distances.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_distances.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_distances.is_bigendian, _x.f_distances.point_step, _x.f_distances.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_distances.is_bigendian = bool(self.f_distances.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_distances.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.f_distances.is_dense, _x.f_confidences.header.seq, _x.f_confidences.header.stamp.secs, _x.f_confidences.header.stamp.nsecs,) = _struct_B3I.unpack(str[start:end])
      self.f_distances.is_dense = bool(self.f_distances.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_confidences.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_confidences.height, _x.f_confidences.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_confidences.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_confidences.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_confidences.is_bigendian, _x.f_confidences.point_step, _x.f_confidences.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_confidences.is_bigendian = bool(self.f_confidences.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_confidences.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.f_confidences.is_dense, _x.f_amplitudes.header.seq, _x.f_amplitudes.header.stamp.secs, _x.f_amplitudes.header.stamp.nsecs,) = _struct_B3I.unpack(str[start:end])
      self.f_confidences.is_dense = bool(self.f_confidences.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_amplitudes.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_amplitudes.height, _x.f_amplitudes.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_amplitudes.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_amplitudes.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_amplitudes.is_bigendian, _x.f_amplitudes.point_step, _x.f_amplitudes.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_amplitudes.is_bigendian = bool(self.f_amplitudes.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_amplitudes.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.f_amplitudes.is_dense, _x.f_normals_azi.header.seq, _x.f_normals_azi.header.stamp.secs, _x.f_normals_azi.header.stamp.nsecs,) = _struct_B3I.unpack(str[start:end])
      self.f_amplitudes.is_dense = bool(self.f_amplitudes.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_normals_azi.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_normals_azi.height, _x.f_normals_azi.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_normals_azi.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_normals_azi.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_normals_azi.is_bigendian, _x.f_normals_azi.point_step, _x.f_normals_azi.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_normals_azi.is_bigendian = bool(self.f_normals_azi.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_normals_azi.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.f_normals_azi.is_dense, _x.f_normals_zen.header.seq, _x.f_normals_zen.header.stamp.secs, _x.f_normals_zen.header.stamp.nsecs,) = _struct_B3I.unpack(str[start:end])
      self.f_normals_azi.is_dense = bool(self.f_normals_azi.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_normals_zen.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_normals_zen.height, _x.f_normals_zen.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_normals_zen.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_normals_zen.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_normals_zen.is_bigendian, _x.f_normals_zen.point_step, _x.f_normals_zen.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_normals_zen.is_bigendian = bool(self.f_normals_zen.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_normals_zen.data = str[start:end]
      start = end
      end += 1
      (self.f_normals_zen.is_dense,) = _struct_B.unpack(str[start:end])
      self.f_normals_zen.is_dense = bool(self.f_normals_zen.is_dense)
      return self
    except struct.error as e:
      raise roslib.message.DeserializationError(e) #most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    @param buff: buffer
    @type  buff: StringIO
    @param numpy: numpy python module
    @type  numpy module
    """
    try:
      _x = self
      buff.write(_struct_3I.pack(_x.f_distances.header.seq, _x.f_distances.header.stamp.secs, _x.f_distances.header.stamp.nsecs))
      _x = self.f_distances.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_distances.height, _x.f_distances.width))
      length = len(self.f_distances.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_distances.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_distances.is_bigendian, _x.f_distances.point_step, _x.f_distances.row_step))
      _x = self.f_distances.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_B3I.pack(_x.f_distances.is_dense, _x.f_confidences.header.seq, _x.f_confidences.header.stamp.secs, _x.f_confidences.header.stamp.nsecs))
      _x = self.f_confidences.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_confidences.height, _x.f_confidences.width))
      length = len(self.f_confidences.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_confidences.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_confidences.is_bigendian, _x.f_confidences.point_step, _x.f_confidences.row_step))
      _x = self.f_confidences.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_B3I.pack(_x.f_confidences.is_dense, _x.f_amplitudes.header.seq, _x.f_amplitudes.header.stamp.secs, _x.f_amplitudes.header.stamp.nsecs))
      _x = self.f_amplitudes.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_amplitudes.height, _x.f_amplitudes.width))
      length = len(self.f_amplitudes.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_amplitudes.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_amplitudes.is_bigendian, _x.f_amplitudes.point_step, _x.f_amplitudes.row_step))
      _x = self.f_amplitudes.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_B3I.pack(_x.f_amplitudes.is_dense, _x.f_normals_azi.header.seq, _x.f_normals_azi.header.stamp.secs, _x.f_normals_azi.header.stamp.nsecs))
      _x = self.f_normals_azi.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_normals_azi.height, _x.f_normals_azi.width))
      length = len(self.f_normals_azi.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_normals_azi.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_normals_azi.is_bigendian, _x.f_normals_azi.point_step, _x.f_normals_azi.row_step))
      _x = self.f_normals_azi.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_B3I.pack(_x.f_normals_azi.is_dense, _x.f_normals_zen.header.seq, _x.f_normals_zen.header.stamp.secs, _x.f_normals_zen.header.stamp.nsecs))
      _x = self.f_normals_zen.header.frame_id
      length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
      _x = self
      buff.write(_struct_2I.pack(_x.f_normals_zen.height, _x.f_normals_zen.width))
      length = len(self.f_normals_zen.fields)
      buff.write(_struct_I.pack(length))
      for val1 in self.f_normals_zen.fields:
        _x = val1.name
        length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x.encode()))
        _x = val1
        buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
      _x = self
      buff.write(_struct_B2I.pack(_x.f_normals_zen.is_bigendian, _x.f_normals_zen.point_step, _x.f_normals_zen.row_step))
      _x = self.f_normals_zen.data
      length = len(_x)
      # - if encoded as a list instead, serialize as bytes instead of string
      if type(_x) in [list, tuple]:
        buff.write(struct.pack('<I%sB'%length, length, *_x))
      else:
        buff.write(struct.pack('<I%ss'%length, length, _x))
      buff.write(_struct_B.pack(self.f_normals_zen.is_dense))
    except struct.error as se: self._check_types(se)
    except TypeError as te: self._check_types(te)

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    @param str: byte array of serialized message
    @type  str: str
    @param numpy: numpy python module
    @type  numpy: module
    """
    try:
      if self.f_distances is None:
        self.f_distances = sensor_msgs.msg.PointCloud2()
      if self.f_confidences is None:
        self.f_confidences = sensor_msgs.msg.PointCloud2()
      if self.f_amplitudes is None:
        self.f_amplitudes = sensor_msgs.msg.PointCloud2()
      if self.f_normals_azi is None:
        self.f_normals_azi = sensor_msgs.msg.PointCloud2()
      if self.f_normals_zen is None:
        self.f_normals_zen = sensor_msgs.msg.PointCloud2()
      end = 0
      _x = self
      start = end
      end += 12
      (_x.f_distances.header.seq, _x.f_distances.header.stamp.secs, _x.f_distances.header.stamp.nsecs,) = _struct_3I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_distances.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_distances.height, _x.f_distances.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_distances.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_distances.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_distances.is_bigendian, _x.f_distances.point_step, _x.f_distances.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_distances.is_bigendian = bool(self.f_distances.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_distances.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.f_distances.is_dense, _x.f_confidences.header.seq, _x.f_confidences.header.stamp.secs, _x.f_confidences.header.stamp.nsecs,) = _struct_B3I.unpack(str[start:end])
      self.f_distances.is_dense = bool(self.f_distances.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_confidences.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_confidences.height, _x.f_confidences.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_confidences.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_confidences.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_confidences.is_bigendian, _x.f_confidences.point_step, _x.f_confidences.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_confidences.is_bigendian = bool(self.f_confidences.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_confidences.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.f_confidences.is_dense, _x.f_amplitudes.header.seq, _x.f_amplitudes.header.stamp.secs, _x.f_amplitudes.header.stamp.nsecs,) = _struct_B3I.unpack(str[start:end])
      self.f_confidences.is_dense = bool(self.f_confidences.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_amplitudes.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_amplitudes.height, _x.f_amplitudes.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_amplitudes.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_amplitudes.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_amplitudes.is_bigendian, _x.f_amplitudes.point_step, _x.f_amplitudes.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_amplitudes.is_bigendian = bool(self.f_amplitudes.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_amplitudes.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.f_amplitudes.is_dense, _x.f_normals_azi.header.seq, _x.f_normals_azi.header.stamp.secs, _x.f_normals_azi.header.stamp.nsecs,) = _struct_B3I.unpack(str[start:end])
      self.f_amplitudes.is_dense = bool(self.f_amplitudes.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_normals_azi.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_normals_azi.height, _x.f_normals_azi.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_normals_azi.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_normals_azi.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_normals_azi.is_bigendian, _x.f_normals_azi.point_step, _x.f_normals_azi.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_normals_azi.is_bigendian = bool(self.f_normals_azi.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_normals_azi.data = str[start:end]
      _x = self
      start = end
      end += 13
      (_x.f_normals_azi.is_dense, _x.f_normals_zen.header.seq, _x.f_normals_zen.header.stamp.secs, _x.f_normals_zen.header.stamp.nsecs,) = _struct_B3I.unpack(str[start:end])
      self.f_normals_azi.is_dense = bool(self.f_normals_azi.is_dense)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_normals_zen.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 8
      (_x.f_normals_zen.height, _x.f_normals_zen.width,) = _struct_2I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.f_normals_zen.fields = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointField()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        val1.name = str[start:end]
        _x = val1
        start = end
        end += 9
        (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
        self.f_normals_zen.fields.append(val1)
      _x = self
      start = end
      end += 9
      (_x.f_normals_zen.is_bigendian, _x.f_normals_zen.point_step, _x.f_normals_zen.row_step,) = _struct_B2I.unpack(str[start:end])
      self.f_normals_zen.is_bigendian = bool(self.f_normals_zen.is_bigendian)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      self.f_normals_zen.data = str[start:end]
      start = end
      end += 1
      (self.f_normals_zen.is_dense,) = _struct_B.unpack(str[start:end])
      self.f_normals_zen.is_dense = bool(self.f_normals_zen.is_dense)
      return self
    except struct.error as e:
      raise roslib.message.DeserializationError(e) #most likely buffer underfill

_struct_I = roslib.message.struct_I
_struct_IBI = struct.Struct("<IBI")
_struct_B = struct.Struct("<B")
_struct_3I = struct.Struct("<3I")
_struct_B3I = struct.Struct("<B3I")
_struct_B2I = struct.Struct("<B2I")
_struct_2I = struct.Struct("<2I")
class FeatureCalculation(roslib.message.ServiceDefinition):
  _type          = 'feature_factory/FeatureCalculation'
  _md5sum = 'd90c5348877c0b5a172d453461340109'
  _request_class  = FeatureCalculationRequest
  _response_class = FeatureCalculationResponse
