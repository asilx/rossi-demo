<launch>

  <include file="$(find openni_launch)/launch/openni.launch"/>

  <param name="robot_description" command="$(find xacro)/xacro.py '$(find al_robots)/defs/human.urdf.xacro'" />

	<node pkg="al_robots" type="human_tf_publisher" name="human_tf_publisher"/>

	<node pkg="robot_self_filter" type="self_filter" respawn="true" output="screen" name="self_filter">
	  <remap from="cloud_in" to="camera/depth/points" />
    <remap from="cloud_out" to="camera/depth/points_self_fltrd" />

     <!-- The frame of the sensor used to obtain the data to be
       filtered; This parameter is optional. If it is not specified,
       shadow points will be considered outside -->
     <param name="sensor_frame" type="string" value="/openni_rgb_optical_frame" />

     <!-- Minimum distance to sensor (for point not to be considered inside) -->
     <param name="min_sensor_dist" type="double" value="0.01" />

     <!-- The padding to be added for the body parts the robot can see -->
     <param name="self_see_padd" type="double" value="0.02" />

     <!-- The scaling to be added for the body parts the robot can see -->
     <param name="self_see_scale" type="double" value="1.0" />
    
         <!-- The names of the links the sensor can see -->
     <!-- The names of the links the sensor can see -->
		<rosparam file="$(find al_robots)/conf/self_filter.yaml" command="load" />
		<param name="subsample_value" type="double" value="0.0"/>
	</node>
</launch>
